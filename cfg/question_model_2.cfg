
# Same as questio_model.cfg 
# BUT with ir:reward = -1

/# cache_host = <hostname or IP address of machine on which ff-plan-cache is running>
cache_host = localhost
# cache_service = <Port number on which ff-plan-cache is listening for TCP connections>
cache_service = 5002
known_world_only = 0
ff_timelimit = 60
training_time_ff_time_limit = 10
test_time_ff_time_limit = 10

use_local_heuristic_evaluator = 0
ignore_predicate_numerics = 1
heuristic_evaluator_rules = ${data_path}/heuristic_evaluation_rules.txt

learning_iterations = 2
test_period = 10
param_save_period = -1
solution_log_period = -1
sequences_on_first_iteration = 1
sequences_per_iteration = 1
max_subgoal_sequence_length = 10
task_completion_reward = 2
plan_failure_penalty = 1
successful_step_reward_base = 0
reward_for_hitting_cache_periphery = 0
unnecessary_subgoal_penalty = 0.1
learn_from_alternate_sequences = 1
learn_on_subgoal_free_problems = 1
remember_solutions = 0
log_predictions = 0
use_pddl_connection_features = 0
use_text_connection_features = 0.5
use_complex_non_connection_features = 0.5
predicate_identity_pair_feature_weight = 1
non_connection_feature_importance = 1
disallow_any_duplicate_subgoals = 1
disallow_neighboring_duplicate_subgoals = 1
use_logarithmic_distance_score = 0
force_connection_weights = 0
forced_connection_weight_to_init = 0
forced_connection_weight_to_target = 0
use_predicate_value_feature = 0
use_reachable_subgoal_feature = 1
use_reachability_equivalents = 1
use_task_completion_text_reward = 0
subgoal_not_in_prefix_reward = 0
use_success_failure_counts_in_feedback = 0
text_updates_per_iteration = 20

log_predictions = 0
log_connection_feedback = 0
log_connection_predictions = 0
data_path = data/
output_path = output/${run}
solution_log_path = output/${run}/solutions
prediction_log_path = output/${run}/predictions.log.
connection_feedback_log_file = output/${run}/feedback.log
connection_prediction_log_file = output/${run}/connection_predictions.log
script_path = ../../scripts/
domain_pddl_file = ${data_path}/domain.pddl
problems_path = ${data_path}/problem-pddls

save_global_feature_map = 0
global_feature_mapping_file = ${output_path}/global.map

end:feature_mapping_file = ${output_path}/sequence_end.map
end:load_weights = 0
end:weights_file = ${output_path}/sequence_end.weight
end:max_weight_ceiling = 1000000
end:retain_weight_history = 0
end:param_save_period = -1

subgoal:feature_mapping_file = ${output_path}/subgoal.map
subgoal:load_weights = 0
subgoal:weights_file = ${output_path}/subgoal.weight
subgoal:max_weight_ceiling = 1000000
subgoal:retain_weight_history = 0
subgoal:param_save_period = -1

connection:feature_mapping_file = ${output_path}/connection.map
connection:load_weights = 0
connection:weights_file = ${output_path}/connection.weight
connection:max_weight_ceiling = 1000000
connection:retain_weight_history = 0
connection:param_save_period = -1

end:learning_rate = 0.0001
end:regularization_factor = 0.1
end:epsilon-min = 0.01
end:epsilon-max = 0.01
end:beta-min = 0.01
end:beta-max = 0.1
end:exploration_type = epsilon-softmax

subgoal:learning_rate = 0.0001
subgoal:regularization_factor = 0.1
subgoal:epsilon-min = 0.01
subgoal:epsilon-max = 0.01
subgoal:beta-min = 0.01
subgoal:beta-max = 0.1
subgoal:exploration_type = epsilon-softmax

connection:learning_rate = 0.02
connection:regularization_factor = 0.1
connection:epsilon-min = 0.01
connection:epsilon-max = 0.1
connection:beta-min = 0.1
connection:beta-max = 1
connection:exploration_type = epsilon-softmax
connection:reward_type = linear
connection:success_reward = 0.3
connection:failure_penalty = 1.8
connection:retain_connection_feedback = 1


pddl_dict_file = ${data_path}/valid_predicates.dictionary
pddl_dict_question_actions_file = ${data_path}/valid_questions_actions.dictionary
pddl_dict_question_objects_file = ${data_path}/valid_questions_objects.dictionary
pddl_dict_question_objectsActions_file = ${data_path}/valid_questions_objectsActions.dictionary
pddl_connection_file = ${data_path}/empty.txt

# ATTENTION: this is written every time by the IR and has to be reset everytime
text_connection_file = ${data_path}/valid_predicates.text_features
ir:text_connection_file = ${data_path}/qa.text_features

use_gold_length = 0
gold_length_file = ${data_path}/empty.txt
features:use_only_previous_subgoal = 1
features:include_init = 0
features:force_conn_weight_high = 0
features:print_text_connection_features = 0
features:debug_features_to_print_file = output/${run}/debug_features.txt

display_ff_progress = 0

test_pddl_features = 0
test_pddl = 0
test_domain = domain.pddl
test_problem = x/1.pddl

copy_binary_to_output_path = 0
dump_source = 0

# Additional Configuration for Question Answering System

#Question-type config
ir:object-questions = 1
ir:action-questions = 1
ir:subgoal-questions = 0
ir:start-end-question = 0
ir:current-end-question = 0
ir:two-subgoals-question = 0

# TODO figure out answer config semantics
ir:answer-corpus = wiki
ir_host = localhost
ir_service = 3456

#Answer type config
ir:random = 0
ir:num_answers = 5

# TODO Implement functionality to support this
ir:log-human-readable-question-answers=1
ir:reward = -1
